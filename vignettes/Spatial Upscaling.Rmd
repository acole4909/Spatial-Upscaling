---
title: "Spatial Upscaling"
author: "Amanda Cole"
date: "2023-12-17"
output:
  html_document:
    code_folding: hide
---
# 2.1 Literature
Random cross-validation is a type of cross-validation (a technqiue where a dataset is split into equally sized subsets or folds) where data is randomly divided into folds^1^. In random cross-validation, data is assumed to be independent and identically distributed and no structure or order of the datset is taken into account. Random division of data into folds causes an issue when structural dependencies, such as spatial autocorrelation (when values of variables that are geographically close to one another are similar) are present in the data^2,3^. In cases where data are geographically clustered and geographically close variables are correlated, spatial cross-validation should be used. In spatial cross-validation, data is divided into folds based on geography. Because spatial cross-validation takes into account the spatial relationships of the data, this can improve model accuracy and applicability^3^.

An alternative to measuring distance as a geographical distance in a Euclidean space that considers the task of spatial upscaling on environmental covariates more directly could be to measure distance by classes within which the data are generated or temporal proximity. In this dataset for example, leaf nitrogen content will differ based on plant species meaning that although two areas of forest may be farther apart in terms of geographical distance, they will present leaf nitrogen content values that are more similar than than an area of forest and a cropland that are close together in terms of geographical distance. In this dataset, covariates of mean temperature and mean daily irradiance will differ temporally. 

# 2.2 Random Cross-Validation
After splitting the dataset into training and test sets (70/30% split respectively), I used the {caret} package to perform a 5-fold cross-validation with the target variable of LeafN and predictor variables of elevation, mean annual temperature, mean annual precipitation, atmospheric nitrogen deposition, mean annual daily irradiance, and species. Hyperparameters were set as mtry=3 and min.node.size=12. 
```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(dplyr)
library(here)
library(knitr)
library(tidyterra)
library(ggplot2)
library(ranger)
library(OneR)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
```

```{r, include=FALSE}
# Load data
dfs <- readRDS(here::here("data-raw/dfs.rds"))

# Split dataset into training and testing sets
set.seed(456)  # for reproducibility
split <- rsample::initial_split(dfs, prop = 0.7)
df_train <- rsample::training(split)
df_test <- rsample::testing(split)

# Filter out any NA to avoid error when running a Random Forest
df_train <- df_train |> tidyr::drop_na()
df_test <- df_test   |> tidyr::drop_na()
```

```{r message=FALSE, warning=FALSE, include=TRUE}
pp <- recipes::recipe(leafN ~ elv+map+mat+ndep+mai+Species, data = df_train) |>
  recipes::step_center(recipes::all_numeric(), -recipes::all_outcomes()) |>
  recipes::step_scale(recipes::all_numeric(), -recipes::all_outcomes())

modcv <- caret::train(
  pp,
  data = df_train |>
    drop_na(),
  method = "ranger",
  trControl = caret::trainControl(method = "cv", number = 5, savePredictions = "final"),
  tuneGrid = expand.grid( .mtry = 3,
                          .min.node.size = 12,
                          .splitrule = "variance"),
  metric = "RMSE",
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 100,
  seed = 456                # for reproducibility
)
```
The RMSE and R^2^ across validation folds are as follows:
```{r echo=FALSE}
metrics_byfold <- modcv$resample
metrics_byfold
```

# 2.3 Spatial Cross Validation
```{r echo=FALSE}
library(ggplot2)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)

# get coast outline
coast <- rnaturalearth::ne_coastline(scale = 110, returnclass = "sf")

ggplot() +

  # plot coastline
  geom_sf(data = coast,
          colour = 'black',
          size = 0.2) +

  # set extent in longitude and latitude
  coord_sf(
    ylim = c(-60, 80),
    expand = FALSE) +  # to draw map strictly bounded by the specified extent
  
  # plot points on map
  geom_point(data = dfs, aes(x = lon, y = lat), color = "red", size = 0.2) +
  labs(x = "", y = "") +
  theme(legend.position = "bottom")
```

As shown above, data are heavily geographically clustered. Using random cross-validation on a dataset that is heavily geographically clustered may produce a model that has poor generalisability, i.e. is not able to make predictions for new locations. Using spatial cross-validation will allow us to produce a model that has an improved ability to make predictions for new locations.  


To perform a spatial cross-validation, I first used the k-means algorithm, setting k=5, to identify geographical clusters of data considering latitude and latitude of the data points as follows:  
```{r echo=TRUE, code_folding='show'}
dfs <- as.data.frame(dfs, cell = TRUE)
clusters <- kmeans(
  dfs[, 2:3],
  centers = 5
)
dfs$cluster <- clusters$cluster
```

The points are plotted on a global map below with the 5 clusters shown in pink, orange, green, blue, and dark yellow.  
```{r echo=FALSE, message=FALSE, warning=FALSE}
# get coast outline
coast <- rnaturalearth::ne_coastline(scale = 110, returnclass = "sf")

p2 <- ggplot() +

  # plot coastline
  geom_sf(data = coast,
          colour = 'black',
          size = 0.2) +

  # set extent in longitude and latitude
  coord_sf(
    ylim = c(-60, 80),
    expand = FALSE) +  # to draw map strictly bounded by the specified extent

  # plot lat and long points on map by cluster
  geom_point(data = dfs, aes(x = lon, y = lat, group=cluster), size = 0.2) +
  scale_color_manual(values = c("1" = "blue", "2" = "green", "3" = "red", "4"="yellow", "5"="pink")) +
  labs(x = "", y = "") +
  theme(legend.position = "bottom")

p2 +
  aes(color = factor(cluster)) +
  scale_color_discrete(name = "Cluster",
                       labels = c("Cluster 1",
                                  "Cluster 2",
                                  "Cluster 3",
                                  "Cluster 4",
                                  "Cluster 5"))

```

The distribution of LeafN by cluster is shown below:
```{r echo=FALSE}
p3 <- ggplot() +

  # plot coastline
  geom_sf(data = coast,
          colour = 'black',
          size = 0.2) +

  # set extent in longitude and latitude
  coord_sf(
    ylim = c(-60, 80),
    expand = FALSE) +  # to draw map strictly bounded by the specified extent

  # plot lat and long points on map by cluster
  geom_point(data = dfs, aes(x = lon, y = lat, group=cluster), color = factor(dfs$leafN), size = 0.2) +
  labs(x = "", y = "") +
  theme(legend.position = "bottom")

p3 +
  aes(color = factor(dfs$leafN)) +
  scale_color_discrete(name = "LeafN",
                       labels = c("LeafN Cluster 1",
                                  "LeafN Cluster 2",
                                  "LeafN Cluster 3",
                                  "LeafN Cluster 4",
                                  "LeafN Cluster 5"))
```

I used the {purrr} package to split the data into five folds corresponding to geographical clustered identified above.
```{r echo=TRUE}
# create folds based on clusters
# assuming 'dfs' contains the data and a column called 'cluster' containing the
# result of the k-means clustering
group_folds_train <- purrr::map(
  seq(length(unique(dfs$cluster))),
  ~ {
    dfs |>
      select(cluster) |>
      mutate(idx = 1:n()) |>
      filter(cluster != .) |>
      pull(idx)
  }
)

group_folds_test <- purrr::map(
  seq(length(unique(dfs$cluster))),
  ~ {
    dfs |>
      select(cluster) |>
      mutate(idx = 1:n()) |>
      filter(cluster == .) |>
      pull(idx)
  }
)
```
I then used the {ranger} package to fit a random forest model with hyperparameters as mtry=3 and min.node.size=12 and performed a 5-fold cross-validation with the clusters as folds to predict for target variable LeafN.

```{r echo=TRUE}
# create a function that trains a random forest model on a given set of rows and
# predicts on a disjunct set of rows

target <- dfs$leafN

train_test_by_fold <- function(dfs, idx_train, idx_val){

  mod <- ranger::ranger(
    x =  dfs[idx_train, 2:9],  # data frame with columns corresponding to predictors
    y =  target[idx_train],  # a vector of the target values (not a data frame!)
  )

  pred <- predict(mod,       # the fitted model object
                  data = dfs[idx_val, 2:9] # a data frame with columns corresponding to predictors
  )

  tmp <- dfs[idx_val,]
  tmp$preds <- predictions(pred)

  rsq <- yardstick::rsq(tmp, "leafN", "preds") # the R-squared determined on the validation set
  rmse <- yardstick::rmse(tmp, "leafN", "preds") # the root mean square error on the validation set

  return(tibble(rsq = rsq, rmse = rmse))
}

# apply function on each custom fold and collect validation results in a nice
# data frame
out <- purrr::map2_dfr(
  group_folds_train,
  group_folds_test,
  ~train_test_by_fold(dfs, .x, .y)
) |>
  mutate(test_fold = 1:5)
```
The RMSE and R^2^ across the five folds are as follows:
```{r echo=FALSE}
out
```
